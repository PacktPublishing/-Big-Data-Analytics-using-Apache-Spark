import org.apache.spark.sql.types._
import org.apache.spark.sql.functions._
val logSchema = new StructType().add("time", TimestampType, false).add("level", StringType, false)
val inputLogStream = spark.readStream.schema(logSchema).option("maxFilesPerTrigger",1).csv("/Users/holyspirit/spark2/logging")
inputLogStream.printSchema()
val windowCountDF = inputLogStream.groupBy(window($"time", "10 minutes"), $"level").count()
val logQuery = windowCountDF.writeStream.format("console").option("truncate", "false").outputMode("complete").start()
